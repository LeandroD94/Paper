##################### PREPARING THE ENVIRONMENT #################

{ library("phyloseq")
library("ggplot2")
library("vegan")
library("ggpubr")
library("ggh4x") #
library("egg")
library("dendextend")
library("DESeq2")
library("mixOmics") #
library("xlsx")  
library("dplyr")
library("stringr")
library("qiime2R")
}

{dir.create("Data_check")
dir.create("Data_check/PCoA_test")
dir.create("Results")
dir.create("Results/Abundances")
dir.create("Results/Hierarchical_clustering")
dir.create("Results/Beta_div")
dir.create("Results/DA_DESeq2/")
dir.create("Results/PICRUST2_LEFSE_results")
}

options(scipen = 100) # disable scientific annotation


####################### IMPORTING DATA #####################

# devtools::install_github("jbisanz/qiime2R")
data<-qza_to_phyloseq(features="QIIME/table.qza", taxonomy="QIIME/taxonomy.qza", tree = "QIIME/rooted-tree.qza")
# changing names
sample<-sample_names(data)
original_names<-sample

Metadata <- as.data.frame(read.csv("metadata.R.csv"))
row.names(Metadata)<-str_split(Metadata$FASTQ_code, pattern = "_", simplify = T)[,1] # to match phyloseq codes
head(Metadata)
original_length<-length(Metadata$FASTQ_code[!is.na(Metadata$FASTQ_code)])
Metadata<-Metadata[sample, ]
identical(as.numeric(length(Metadata$FASTQ_code[!is.na(Metadata$FASTQ_code)])),as.numeric(original_length))

sample_data(data)<-Metadata
identical(as.numeric(length(sample_names(data))),as.numeric(length(original_names)))

rm(original_length,original_names,sample)

sample_data(data)$Condition<-factor(sample_data(data)$Condition, levels=c("SSc","VEDOSS")) # decides the order in plots
sample_names(data)<-sample_data(data)$Sample_name
head(sample_data(data))

# save.image("data_scleroderm_2022.RData")


#################### FILTERING NOISES FROM DATA SET ####################

unfiltered_data<-data

###### cutting under 0.01% to remove noises/contaminants (a too conservative but also safe cutoff, see  DOI: 10.1128/mSystems.00290-19)
data.genus.temp<-tax_glom(data, taxrank = "Genus")
data.genus.temp<-transform_sample_counts(data.genus.temp, function(x) (x/sum(x))*100)
filtered<-taxa_names(filter_taxa(data.genus.temp, function(x) max(x) <= 0.01, TRUE))
write.csv( cbind(as.data.frame(tax_table(data.genus.temp))[filtered, c("Phylum","Family","Genus")], as.data.frame(otu_table(data.genus.temp))[filtered, ] ), 
           file="Data_check/Filtered_genus_under_001_cutoff.csv")

filtered<-as.data.frame(tax_table(filter_taxa(data.genus.temp, function(x) max(x) <= 0.01, TRUE)))[["Genus"]]
filtered
filtered<-filtered[filtered!="uncultured"] # to avoid the remotion of other uncultured genera
data<-subset_taxa(data, ! Genus %in% filtered)
rm(filtered, data.genus.temp)

######## Checking unassigned in prokaryote kingdom
{Unass<-tax_glom(data, taxrank = "Kingdom") # or domain
  Unass.prop<-transform_sample_counts(Unass, function (x) (x/sum(x)*100) )
  a<-cbind( apply(otu_table(Unass), sum, MARGIN = 1) )
  total<-sum(a)
  b<-cbind( (a/total)*100, apply(otu_table(Unass), min, MARGIN = 1) , apply(otu_table(Unass), max, MARGIN = 1 ) )
  c<-otu_table(Unass)
  c_a<-NULL
  for(x in 1:length(row.names(c))) {
    c_a<-c(c_a,colnames(c)[which.min(c[x,])]) }
  c_b<-NULL
  for(x in 1:length(row.names(c))) {
    c_b<-c(c_b,colnames(c)[which.max(c[x,])]) }
  d<-as(tax_table(Unass),"matrix")
  e<-cbind.data.frame(a,b, c_a, c_b, d[,"Kingdom"])
  colnames(e)<-c("total_ASV_count","Percent_proportion","Minor_count_among_samples","Major_count_among_samples", "FASTQ_with_less_count","FASTQ_with_more_count","Kingdom")
  e$Kingdom<-gsub("d__","",e$Kingdom)
  row.names(e)<-e$Kingdom
}
e
write.csv2(e[,colnames(e)!="Kingdom"], file="Data_check/Unassigned_domain_checking.csv", row.names = T, quote = F)
####### now filtering out every Unassigned ASV
data<- subset_taxa(data, Kingdom != "d__Eukaryota")
head(tax_table(data))
write.csv2(tax_table(data), file="Data_check/Every_filtered_ASV_and_taxonomic_assignment.csv", row.names = T)
rm(a,b,c,c_a,c_b,d,e,total,Unass,Unass.prop,x)


############################ RAREFACTION ANALYSIS ################################

evalslopes<-function(x,names,lim=0.5,t=10,cex=0.5) {
  #x: the rarefaction curve as generated by rarecurve (with label=F)
  #lim: the threshold of the slope value to accept saturation
  #b: how long the rarefaction tail should be evaluated (e.g. the last 10 points)
  #names: the labels (the same used of he original samples (and in the same order!!!)
  sat<-0
  for (i in 1:length(x)) {
    v<-as.vector(x[[i]])
    dx<-as.numeric(gsub("N","",names(x[[1]])[2]))-1
    check<-"red"
    if(length(x) < 10) {
      points(as.numeric(rev(gsub("N","",names(x[[i]])))[1]),v[1],col="cyan",pch=16,cex=1)
    } else {
      #the slope is estimated (average) at the last b rarefaction points
      slope<-mean(diff(v[(length(v)-t):length(v)])/dx)
      if(slope<lim) {
        check<-"blue"
        sat = sat+1
      }
      cat(i,slope,check,"\n")
      #			text(as.numeric(rev(gsub("N","",names(x[[i]])))[1]),v[1],labels=slope,col=check,cex=0.5)
      #			points(as.numeric(rev(gsub("N","",names(x[[i]])))[1]),v[1],col=check,pch=16,cex=1)
      text(as.numeric(rev(gsub("N","",names(x[[i]])))[1]),rev(v)[1],col=check,pch=16,cex=cex,labels=names[i])
    }
  }
  legend("bottomright",paste(sat,"saturated samples"),bty="n")
}

png(file="Data_check/Rarefaction_curve.png",width=3000,height=2100, res=300)
r<-rarecurve(t(otu_table(data)), step=100,label=F)
evalslopes(r,sample_names(data),lim=0.001,cex=1)
dev.off()
rm(r)


####################### PREPARATION OF THE DATA #######################

{data.phy = tax_glom(data, taxrank = "Phylum", NArm = F)
data.class = tax_glom(data, taxrank = "Class", NArm = F)
data.order = tax_glom(data, taxrank = "Order", NArm = F)
data.fam = tax_glom(data, taxrank = "Family", NArm = F)
data.genus = tax_glom(data, taxrank = "Genus", NArm = F)
}

{ data.prop <- transform_sample_counts(data, function(ASV) ASV/sum(ASV)*100)
data.phy.prop <- transform_sample_counts(data.phy, function(ASV) ASV/sum(ASV)*100)
data.class.prop <- transform_sample_counts(data.class, function(ASV) ASV/sum(ASV)*100)
data.order.prop <- transform_sample_counts(data.order, function(ASV) ASV/sum(ASV)*100)
data.fam.prop <- transform_sample_counts(data.fam, function(ASV) ASV/sum(ASV)*100)
data.genus.prop <- transform_sample_counts(data.genus, function(ASV) ASV/sum(ASV)*100)
}

{ Taxa.genus<-as.data.frame(tax_table(data.genus))
Taxa.fam<-as.data.frame(tax_table(data.fam))
Taxa.phy<-as.data.frame(tax_table(data.phy))
Taxa.class<-as.data.frame(tax_table(data.class))
Taxa.order<-as.data.frame(tax_table(data.order))
}

# adding informations to missing names
taxa_temp<-Taxa.genus
{for( x in 1: length(which(taxa_temp$Genus=="uncultured")) ) {
  taxa_temp$Genus[which(taxa_temp$Genus=="uncultured")[1]]<-paste("uncultured_ f",taxa_temp[which(taxa_temp$Genus=="uncultured")[1],"Family"])}
for( x in 1: length(which(taxa_temp=="uncultured_ f uncultured")) ) {
  taxa_temp$Genus[ which(taxa_temp$Genus=="uncultured_ f uncultured")[1] ]<-paste("uncultured_ o",taxa_temp[which(taxa_temp$Genus=="uncultured_ f uncultured")[1],"Order"])}
for( x in 1: length(which(is.na(taxa_temp$Genus))) ) {
  taxa_temp$Genus[ which(is.na(taxa_temp$Genus))[1] ]<-paste("NA_ f",taxa_temp[which(is.na(taxa_temp$Genus))[1],"Family"])}
for( x in 1: length(which(taxa_temp=="NA_ f NA")) ) {
  taxa_temp$Genus[ which(taxa_temp$Genus=="NA_ f NA")[1] ]<-paste("NA_ o",taxa_temp[which(taxa_temp$Genus=="NA_ f NA")[1],"Order"])}
for( x in 1: length(which(duplicated(taxa_temp$Genus[taxa_temp$Genus=="NA_ o NA"]))) ) {
  taxa_temp$Genus[ which(taxa_temp$Genus=="NA_ o NA")[1] ]<-paste("NA_ o NA",x+1) }
Taxa.genus.update<-taxa_temp
}

rm(taxa_temp)

#################### % ASSIGNED IN SILVA #########################

{a<-cbind(length(Taxa.genus$Genus),length(which(!is.na(Taxa.genus$Genus))),length(which(!is.na(Taxa.genus$Genus)))/length(Taxa.genus$Genus),"Genus")
b<-cbind(length(Taxa.fam$Family),length(which(!is.na(Taxa.fam$Family))),length(which(!is.na(Taxa.fam$Family)))/length(Taxa.fam$Family),"Family")
c<-cbind(length(Taxa.order$Order),length(which(!is.na(Taxa.order$Order))),length(which(!is.na(Taxa.order$Order)))/length(Taxa.order$Order),"Order")
d<-cbind(length(Taxa.class$Class),length(which(!is.na(Taxa.class$Class))),length(which(!is.na(Taxa.class$Class)))/length(Taxa.class$Class),"Class")
e<-cbind(length(Taxa.phy$Phylum),length(which(!is.na(Taxa.phy$Phylum))),length(which(!is.na(Taxa.phy$Phylum)))/length(Taxa.phy$Phylum),"Phylum")
assigned<-rbind.data.frame(a,b,c,d,e)
colnames(assigned)<-c("Total","Assigned","%","Taxa")
}
assigned
write.csv2(assigned,file="Data_check/Percentual_of_taxa_assigned_in_database.csv",row.names = F, quote = F)
rm(a,b,c,d,e,assigned)

######################## GOOD'S COVERAGE ESTIMATOR #########################

filter<-prune_taxa(taxa_sums(data)==1, data)
length(which(taxa_sums(data)==1)) # if zero there are no singletons
{n<-as.data.frame(otu_table(filter))
  N<-as.data.frame(otu_table(data))
  G<-1-(colSums(n)/colSums(N))
}
con<-file("Data_check/Percentuale_di_singletons_Good's_coverage.txt")
sink(con)
cat("GOOD'S COVERAGE ESTIMATOR \n", fill=TRUE)
cat("1-(n/N) for each sample, where n is number of singletons and N is Total ASV \n \n", fill=TRUE)
G
sink()
close(con)

rm(con, filter, G, n, N)


############## CHECKING THE COMPOSITION AFTER FILTERING ################

data.unf.prop<-transform_sample_counts(unfiltered_data, function(x) (x/sum(x))*100)


############# BRAY HELLINGER

##### unfiltered BRAY
suppressWarnings(rm(data.prop.labels, data.sqrt_prop))
data.prop.labels<-data.unf.prop
{data.sqrt_prop<-transform_sample_counts(data.prop.labels, sqrt) # square root of proportion
  DistBC = phyloseq::distance(data.sqrt_prop, method = "bray")
  ordBC = ordinate(data.sqrt_prop, method = "PCoA", distance = DistBC)
  eigval<-ordBC$values$Eigenvalues # to get eigen values of every PC
  eigval<- round((eigval/sum(eigval))*100, 1) # to get variation explained by every PC
}
p1<-plot_ordination(data.sqrt_prop, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  guides(color="none") +
  geom_point(size=3) + theme_classic(base_size = 14) + stat_ellipse(size=0.2) + 
  geom_text(aes(label=sample_data(data.sqrt_prop)$Sample_name), 
            color="black", size=2.5, show.legend = FALSE) +
  labs(title="PCoA Bray-Curtis (on Hellinger transformed ASV)\n\n UNfiltered data", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"))

##### filtered BRAY
suppressWarnings(rm(data.prop.labels, data.sqrt_prop))
data.prop.labels<-data.prop
{data.sqrt_prop<-transform_sample_counts(data.prop.labels, sqrt) # square root of proportion
  DistBC = phyloseq::distance(data.sqrt_prop, method = "bray")
  ordBC = ordinate(data.sqrt_prop, method = "PCoA", distance = DistBC)
  eigval<-ordBC$values$Eigenvalues # to get eigen values of every PC
  eigval<- round((eigval/sum(eigval))*100, 1) # to get variation explained by every PC
}
p2<-plot_ordination(data.sqrt_prop, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  geom_point(size=3) + theme_classic(base_size = 14) + stat_ellipse(size=0.2) + 
  geom_text(aes(label=sample_data(data.sqrt_prop)$Sample_name), 
            color="black", size=2.5, show.legend = FALSE) +
  labs(title="\n \n filtered data", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"))

png(filename = "Data_check/PCoA_test/PCoA_BRAY_test.png", width = 3200, height = 1800, res=300)
ggarrange(p1,p2, nrow = 1)
dev.off()

suppressWarnings(rm(p1,p2,data.sqrt_prop,eigval,ordBC,DistBC,data.prop.labels))


############# sqrt BRAY PROPORTIONAL AB

##### unfiltered sqrt BRAY
suppressWarnings(rm(data.prop.labels, data.sqrt_prop))
data.prop.labels<-data.unf.prop
{DistBC = phyloseq::distance(data.prop.labels, method = "bray")
  DistBC = sqrt(DistBC)
  ordBC = ordinate(data.prop.labels, method = "PCoA", distance = DistBC)
  eigval<-ordBC$values$Eigenvalues # to get eigen values of every PC
  eigval<- round((eigval/sum(eigval))*100, 1) # to get variation explained by every PC
}
p1<-plot_ordination(data.prop.labels, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  guides(color="none") +
  geom_point(size=3) + theme_classic(base_size = 14) + stat_ellipse(size=0.2) + 
  geom_text(aes(label=sample_data(data.prop.labels)$Sample_name), 
            color="black", size=2.5, show.legend = FALSE) +
  labs(title="PCoA sqrt Bray-Curtis (on proportional ASV)\n\n UNfiltered data", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"))

##### filtered BRAY
suppressWarnings(rm(data.prop.labels, data.prop.labels))
data.prop.labels<-data.prop
{DistBC = phyloseq::distance(data.prop.labels, method = "bray")
  DistBC = sqrt(DistBC)
  ordBC = ordinate(data.prop.labels, method = "PCoA", distance = DistBC)
  eigval<-ordBC$values$Eigenvalues # to get eigen values of every PC
  eigval<- round((eigval/sum(eigval))*100, 1) # to get variation explained by every PC
}
p2<-plot_ordination(data.prop.labels, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  geom_point(size=3) + theme_classic(base_size = 14) + stat_ellipse(size=0.2) + 
  geom_text(aes(label=sample_data(data.prop.labels)$Sample_name), 
            color="black", size=2.5, show.legend = FALSE) +
  labs(title="\n \n filtered data", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"))

png(filename = "Data_check/PCoA_test/PCoA_sqrt_BRAY_test.png", width = 3200, height = 1800, res=300)
ggarrange(p1,p2, nrow = 1)
dev.off()

suppressWarnings(rm(p1,p2,data.sqrt_prop,eigval,ordBC,DistBC,data.prop.labels))


############# EUCLIDEAN HELLINGER

##### unfiltered EUCLIDEAN
suppressWarnings(rm(data.prop.labels, data.sqrt_prop, p1))
data.prop.labels<-data.unf.prop
{data.sqrt_prop<-transform_sample_counts(data.prop.labels, sqrt) # square root of proportion
  DistBC = phyloseq::distance(data.sqrt_prop, method = "euclidean")
  ordBC = ordinate(data.sqrt_prop, method = "PCoA", distance = DistBC)
  eigval<-ordBC$values$Eigenvalues # to get eigen values of every PC
  eigval<- round((eigval/sum(eigval))*100, 1) # to get variation explained by every PC
}
p1<-plot_ordination(data.sqrt_prop, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  guides(color="none") +
  geom_point(size=3) + theme_bw(base_size = 14) + stat_ellipse(size=0.2) + 
  geom_text(aes(label=sample_data(data.sqrt_prop)$Sample_name), 
            color="black", size=2.5, show.legend = FALSE) +
  labs(title="PCoA Euclidean (on Hellinger transformed ASV)\n\n UNfiltered data", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"))

##### filtered EUCLIDEAN
suppressWarnings(rm(data.prop.labels, data.sqrt_prop))
data.prop.labels<-data.prop
{data.sqrt_prop<-transform_sample_counts(data.prop.labels, sqrt) # square root of proportion
  DistBC = phyloseq::distance(data.sqrt_prop, method = "euclidean")
  ordBC = ordinate(data.sqrt_prop, method = "PCoA", distance = DistBC)
  eigval<-ordBC$values$Eigenvalues # to get eigen values of every PC
  eigval<- round((eigval/sum(eigval))*100, 1) # to get variation explained by every PC
}
p2<-plot_ordination(data.sqrt_prop, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  geom_point(size=3) + theme_bw(base_size = 14) + stat_ellipse(size=0.2) + 
  geom_text(aes(label=sample_data(data.sqrt_prop)$Sample_name), 
            color="black", size=2.5, show.legend = FALSE) +
  labs(title="\n \n filtered data", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"))

png(filename = "Data_check/PCoA_test/PCoA_hellinger_test.png", width = 3200, height = 1800, res=300)
ggarrange(p1,p2, nrow = 1)
dev.off()

suppressWarnings(rm(p1,p2,data.sqrt_prop,eigval,ordBC,DistBC,data.prop.labels))


####################### PREPARATION OF THE DATA #######################

{data.phy = tax_glom(data, taxrank = "Phylum", NArm = F)
data.class = tax_glom(data, taxrank = "Class", NArm = F)
data.order = tax_glom(data, taxrank = "Order", NArm = F)
data.fam = tax_glom(data, taxrank = "Family", NArm = F)
data.genus = tax_glom(data, taxrank = "Genus", NArm = F)
}

{ data.prop <- transform_sample_counts(data, function(ASV) ASV/sum(ASV)*100)
  data.phy.prop <- transform_sample_counts(data.phy, function(ASV) ASV/sum(ASV)*100)
  data.class.prop <- transform_sample_counts(data.class, function(ASV) ASV/sum(ASV)*100)
  data.order.prop <- transform_sample_counts(data.order, function(ASV) ASV/sum(ASV)*100)
  data.fam.prop <- transform_sample_counts(data.fam, function(ASV) ASV/sum(ASV)*100)
  data.genus.prop <- transform_sample_counts(data.genus, function(ASV) ASV/sum(ASV)*100)
}

{ Taxa.genus<-as.data.frame(tax_table(data.genus))
  Taxa.fam<-as.data.frame(tax_table(data.fam))
  Taxa.phy<-as.data.frame(tax_table(data.phy))
  Taxa.class<-as.data.frame(tax_table(data.class))
  Taxa.order<-as.data.frame(tax_table(data.order))
}

# adding informations to missing names
taxa_temp<-Taxa.genus
{for( x in 1: length(which(taxa_temp$Genus=="uncultured")) ) {
  taxa_temp$Genus[which(taxa_temp$Genus=="uncultured")[1]]<-paste("uncultured_ f",taxa_temp[which(taxa_temp$Genus=="uncultured")[1],"Family"])}
  for( x in 1: length(which(taxa_temp=="uncultured_ f uncultured")) ) {
    taxa_temp$Genus[ which(taxa_temp$Genus=="uncultured_ f uncultured")[1] ]<-paste("uncultured_ o",taxa_temp[which(taxa_temp$Genus=="uncultured_ f uncultured")[1],"Order"])}
  for( x in 1: length(which(is.na(taxa_temp$Genus))) ) {
    taxa_temp$Genus[ which(is.na(taxa_temp$Genus))[1] ]<-paste("NA_ f",taxa_temp[which(is.na(taxa_temp$Genus))[1],"Family"])}
  for( x in 1: length(which(taxa_temp=="NA_ f NA")) ) {
    taxa_temp$Genus[ which(taxa_temp$Genus=="NA_ f NA")[1] ]<-paste("NA_ o",taxa_temp[which(taxa_temp$Genus=="NA_ f NA")[1],"Order"])}
  for( x in 1: length(which(duplicated(taxa_temp$Genus[taxa_temp$Genus=="NA_ o NA"]))) ) {
    taxa_temp$Genus[ which(taxa_temp$Genus=="NA_ o NA")[1] ]<-paste("NA_ o NA",x+1) }
  Taxa.genus.update<-taxa_temp
}

rm(taxa_temp)

#################### % ASSIGNED IN SILVA #########################

{a<-cbind(length(Taxa.genus$Genus),length(which(!is.na(Taxa.genus$Genus))),length(which(!is.na(Taxa.genus$Genus)))/length(Taxa.genus$Genus),"Genus")
b<-cbind(length(Taxa.fam$Family),length(which(!is.na(Taxa.fam$Family))),length(which(!is.na(Taxa.fam$Family)))/length(Taxa.fam$Family),"Family")
c<-cbind(length(Taxa.order$Order),length(which(!is.na(Taxa.order$Order))),length(which(!is.na(Taxa.order$Order)))/length(Taxa.order$Order),"Order")
d<-cbind(length(Taxa.class$Class),length(which(!is.na(Taxa.class$Class))),length(which(!is.na(Taxa.class$Class)))/length(Taxa.class$Class),"Class")
e<-cbind(length(Taxa.phy$Phylum),length(which(!is.na(Taxa.phy$Phylum))),length(which(!is.na(Taxa.phy$Phylum)))/length(Taxa.phy$Phylum),"Phylum")
assigned<-rbind.data.frame(a,b,c,d,e)
colnames(assigned)<-c("Total","Assigned","%","Taxa")
}
assigned
write.csv2(assigned,file="Data_check/Percentual_of_taxa_assigned_in_database.csv",row.names = F, quote = F)
rm(a,b,c,d,e,assigned)


######################## GOOD'S COVERAGE ESTIMATOR #########################

filter<-prune_taxa(taxa_sums(data)==1, data)
length(which(taxa_sums(data)==1)) # if zero there are no singletons
{n<-as.data.frame(otu_table(filter))
  N<-as.data.frame(otu_table(data))
  G<-1-(colSums(n)/colSums(N))
}
con<-file("Data_check/Percentuale_di_singletons_Good's_coverage.txt")
sink(con)
cat("GOOD'S COVERAGE ESTIMATOR \n", fill=TRUE)
cat("1-(n/N) for each sample, where n is number of singletons and N is Total ASV \n \n", fill=TRUE)
G
sink()
close(con)

rm(con, filter, G, n, N)

########################### COUNTS EXPORT ##########################################

dir.create("Results/Abundances/Raw_counts")
{write.csv2(cbind(as(otu_table(data),"matrix"),as(tax_table(data),"matrix")),file="Results/Abundances/Raw_counts/counts_otu.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.phy),"matrix"),as(tax_table(data.phy),"matrix")),file="Results/Abundances/Raw_counts/counts_phylum.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.class),"matrix"),as(tax_table(data.class),"matrix")),file="Results/Abundances/Raw_counts/counts_class.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.order),"matrix"),as(tax_table(data.order),"matrix")),file="Results/Abundances/Raw_counts/counts_order.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.fam),"matrix"),as(tax_table(data.fam),"matrix")),file="Results/Abundances/Raw_counts/counts_family.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.genus),"matrix"),as(tax_table(data.genus),"matrix")),file="Results/Abundances/Raw_counts/counts_genus.csv",quote=F)
}

write.csv2(cbind(as(otu_table(unfiltered_data),"matrix"),as(tax_table(unfiltered_data),"matrix")),file="Data_check/OTU_Unfiltered_abundances_and_tax.csv",quote=F)

options(scipen = 100)
dir.create("Results/Abundances/Relative_abundances")
{write.csv2(cbind(as(otu_table(data.phy.prop),"matrix"),as(tax_table(data.phy),"matrix")),file="Results/Abundances/Relative_abundances/counts_phylum.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.class.prop),"matrix"),as(tax_table(data.class),"matrix")),file="Results/Abundances/Relative_abundances/counts_class.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.order.prop),"matrix"),as(tax_table(data.order),"matrix")),file="Results/Abundances/Relative_abundances/counts_order.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.fam.prop),"matrix"),as(tax_table(data.fam),"matrix")),file="Results/Abundances/Relative_abundances/counts_family.csv",quote=F)
  write.csv2(cbind(as(otu_table(data.genus.prop),"matrix"),as(tax_table(data.genus),"matrix")),file="Results/Abundances/Relative_abundances/counts_genus.csv",quote=F)
  write.xlsx(cbind(as(otu_table(data.genus.prop),"matrix"),as(tax_table(data.genus),"matrix")),file="Results/Abundances/Relative_abundances/counts_genus.xlsx",showNA = F, col.names = T)
  write.xlsx(cbind(as(otu_table(data.phy.prop),"matrix"),as(tax_table(data.phy),"matrix")),file="Results/Abundances/Relative_abundances/counts_phylum.xlsx",showNA = F, col.names = T)
}

###################### ABUNDANCES BAR PLOT ##########################

# choosing colors  (see grDevices::colors() )
fill_color_5<-c("coral","springgreen3","gold3","firebrick3","deepskyblue3","darkslategray3") # "others" will be setted as the last one
fill_color_8<-c("wheat3","darkmagenta","coral","yellow2","firebrick3","springgreen2","violet","deepskyblue2","darkslategray3") # "others" will be setted as the last one

# TOP 5 Phyla
suppressWarnings(rm(top, others, tabella))
{top <- names(sort(taxa_sums(data.phy.prop), decreasing=TRUE))[1:5]
  prune.dat_top <- prune_taxa(top,data.phy.prop)
  others<-taxa_names(data.phy.prop)
  others<-others[!(others %in% top)]
  prune.data.others<-prune_taxa(others,data.phy.prop)
  tabella_top<-psmelt(prune.dat_top)
  tabella_others<-psmelt(prune.data.others)
  tabella_others$Phylum<-"Others"
  tabella<-rbind.data.frame(tabella_top,tabella_others)
  tabella<-tabella[order(sort(tabella$Abundance, decreasing = T)), ]
  tabella$Phylum<-factor(tabella$Phylum, levels = c(unique(tabella$Phylum)[unique(tabella$Phylum)!="Others"],"Others"))
}
# tabella$Condition<-gsub("VEDOSS"," ",tabella$Condition)              # if it is needed to rename
ggplot(data=tabella, aes(x=Sample, y=Abundance, fill=Phylum)) + facet_grid(cols= vars(Condition),scales = "free_x", space = "free_x") + 
  geom_bar(stat="identity", position="stack") + theme_classic(base_size =14) +
  scale_fill_manual(values=fill_color_5) +
  theme(axis.text.x=element_text(angle=90, vjust=0.5), 
        legend.key.size = unit(0.4, "cm"),legend.text = element_text ( size = 12 )) + 
  theme(legend.position="bottom") + guides(fill=guide_legend(nrow=2)) +
  labs(x="Patients", y="Relative abundance", title = "Five most abundant phyla", caption = " 'Others' includes every phylum below rank 5 ")
ggsave(file="Results/Abundances/TOP_5_phyla.png",width=9,height=5, dpi=300)
dev.off()

rm(tabella,prune.data.others, prune.dat_top, tabella_top, tabella_others, top, others)

# TOP 5 Genera
{top <- names(sort(taxa_sums(data.genus.prop), decreasing=TRUE))[1:5]
  prune.dat_top <- prune_taxa(top,data.genus.prop)
  tax_selected<-as.data.frame(tax_table(prune.dat_top))
  tax_selected<-Taxa.genus.update[row.names(tax_selected),]
  tax_table(prune.dat_top)<-as.matrix(tax_selected)
  others<-taxa_names(data.genus.prop)
  others<-others[!(others %in% top)]
  prune.data.others<-prune_taxa(others,data.genus.prop)
  tabella_top<-psmelt(prune.dat_top)
  tabella_others<-psmelt(prune.data.others)
  tabella_others$Genus<-"Others"
  tabella<-rbind.data.frame(tabella_top,tabella_others)
  tabella<-tabella[order(sort(tabella$Abundance, decreasing = T)), ]
  tabella$Genus<-factor(tabella$Genus, levels = c(unique(tabella$Genus)[unique(tabella$Genus)!="Others"],"Others"))
}
ggplot(data=tabella, aes(x=Sample, y=Abundance, fill=Genus)) + facet_grid(cols= vars(Condition),scales = "free_x", space = "free_x") +
  geom_bar(stat="identity", position="stack") + theme_classic(base_size =14) +
  scale_fill_manual(values=fill_color_5) +
  theme(axis.text.x=element_text(angle=90, vjust=0.5), 
        legend.key.size = unit(0.4, "cm"),legend.text = element_text ( size = 12 )) +
  theme(legend.position="bottom") + guides(fill=guide_legend(nrow=2)) + 
  labs(x="Patients", y="Relative abundance", title = "Five most abundant genera", caption = " 'Others' includes every genus below rank 5 ")
ggsave(file="Results/Abundances/TOP_5_genera.png",width=9,height=5,dpi=300)
dev.off()

rm(top, tabella, tabella_top)

# TOP 8 Genera
{top <- names(sort(taxa_sums(data.genus.prop), decreasing=TRUE))[1:8]
  prune.dat_top <- prune_taxa(top,data.genus.prop)
  tax_selected<-as.data.frame(tax_table(prune.dat_top))
  tax_selected<-Taxa.genus.update[row.names(tax_selected),]
  tax_table(prune.dat_top)<-as.matrix(tax_selected)
  others<-taxa_names(data.genus.prop)
  others<-others[!(others %in% top)]
  prune.data.others<-prune_taxa(others,data.genus.prop)
  tabella_top<-psmelt(prune.dat_top)
  tabella_others<-psmelt(prune.data.others)
  tabella_others$Genus<-"Others"
  tabella<-rbind.data.frame(tabella_top,tabella_others)
  tabella<-tabella[order(sort(tabella$Abundance, decreasing = T)), ]
  tabella$Genus<-factor(tabella$Genus, levels = c(unique(tabella$Genus)[unique(tabella$Genus)!="Others"],"Others"))
}
ggplot(data=tabella, aes(x=Sample, y=Abundance, fill=Genus)) + facet_grid(cols= vars(Condition),scales = "free_x", space = "free_x") +
  geom_bar(stat="identity", position="stack") + theme_classic(base_size =14) +
  scale_fill_manual(values=fill_color_8) +
  theme(axis.text.x=element_text(angle=90, vjust=0.5), 
        legend.key.size = unit(0.4, "cm"),legend.text = element_text ( size = 12 )) +
  theme(legend.position="bottom") + guides(fill=guide_legend(nrow=3)) + 
  labs(x="Patients", y="Relative abundance", title = "Eigth most abundant genera", caption = " 'Others' includes every genus below rank 8 ")
ggsave(file="Results/Abundances/TOP_8_genera.png",width=9,height=5,dpi=300)
dev.off()

suppressWarnings(rm(tabella,prune.data.others, prune.dat_top, tabella_top, tabella_others, top, others))


#################### RATIO FIRMICUTES/BACTEROIDES ###################

suppressWarnings(rm(data_fb, ratio_fb))
data_fb<-subset_taxa(data.phy.prop, Phylum %in% c("Bacteroidota","Firmicutes"))
F_index<-grep("Firmicutes",tax_table(data_fb)[,"Phylum"])
B_index<-grep("Bacteroidota",tax_table(data_fb)[,"Phylum"])
ratio_fb<-cbind.data.frame(otu_table(data_fb),tax_table(data_fb)[,"Phylum"])
ratio_fb<-otu_table(data_fb)
ratio_fb <- rbind.data.frame(ratio_fb, as.vector(ratio_fb[F_index,])/as.vector(ratio_fb[B_index,]) )
row.names(ratio_fb)<-c(as.vector(tax_table(data_fb)[,"Phylum"]) , "Ratio")
ratio_fb<-t(ratio_fb)

# name_match<-str_split(Metadata$FASTQ_code, pattern = "_", simplify = T)[,1]
name_match<-Metadata$Sample_name
ratio_fb<-ratio_fb[name_match, ] # same order
identical(length(row.names(ratio_fb)),length(sample_names(data_fb))) # TRUE
ratio_fb<-cbind.data.frame(ratio_fb,Metadata[,c("Sample_name","Condition")])

# mean
Ratios_Mean<-tapply(ratio_fb$Ratio, ratio_fb$Condition, mean)
ratio_fb$Ratios_Mean<-rep("temp")
ratio_fb[ratio_fb$Condition=="VEDOSS","Ratios_Mean"]<-Ratios_Mean["VEDOSS"]
ratio_fb[ratio_fb$Condition=="SSc","Ratios_Mean"]<-Ratios_Mean["SSc"]
ratio_fb$Ratios_Mean<-as.numeric(ratio_fb$Ratios_Mean)
# st err
Ratios_st<-tapply(ratio_fb$Ratio, ratio_fb$Condition, sd)
ratio_fb$Ratios_st_err<-rep("temp")
ratio_fb[ratio_fb$Condition=="VEDOSS","Ratios_st_err"]<-Ratios_st["VEDOSS"]/sqrt(length(which(ratio_fb$Condition=="VEDOSS")))
ratio_fb[ratio_fb$Condition=="SSc","Ratios_st_err"]<-Ratios_st["SSc"]/sqrt(length(which(ratio_fb$Condition=="SSc")))
ratio_fb$Ratios_st_err<-as.numeric(ratio_fb$Ratios_st_err)

head(ratio_fb, n=2)
write.csv2(file="Results/Abundances/Ratio_Firmi_Bacteroi/Firmi_Bacter_Ratio.csv", ratio_fb)

ratio_fb$Condition<-factor(ratio_fb$Condition, levels = c("VEDOSS","SSc"))


####### STATISTICAL TEST

shapiro.test(ratio_fb[,"Ratio"])
#hist(ratio_fb[,"Ratio"])

res<-wilcox.test(Ratio ~ Condition, paired=F, data=ratio_fb)
p_val<-round(res$p.value, digits = 2)
p_val
# exporting the results
con <- file("Results/Abundances/Ratio_Firmi_Bacteroi/Mann_Whi_Wilcoxon.txt") # create this file and connect it to R through "con" object 
sink(con, append = TRUE) # redirect STR ERROR to "con"
cat("Mann_Whitney_Wilcoxon test \n", fill=T)
cat("Ratio~Condition:   V=",res$statistic, "p-value=", p_val, "\n",fill=T)
sink()
close(con)


######## BAR PLOT
ggplot(data=ratio_fb, aes(x=Sample_name, fill=Condition, y=Ratio)) +
  theme_bw(base_size =12) + 
  scale_fill_manual(values = c("SSc"="coral",
                               "VEDOSS"="chartreuse")) +
  facet_grid2(.~Condition, scales = "free_x", 
              space="free", strip = strip_nested(size="constant"))+
  theme(panel.spacing.x = unit(2,"pt"))+
  scale_x_discrete (expand = c(0.01,0) ) +
  geom_line(aes(y= ratio_fb$Ratios_Mean, group="Condition"))+
  # scale_y_sqrt(breaks=c(1,5,seq(10,80,10)) ) +
  scale_y_continuous(breaks=c(0,0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2)) +
  geom_bar(stat="identity", position="stack", width = 0.8) +
  guides(fill="none") +
  theme(axis.text.x=element_text(angle=90, hjust = 1, vjust=0.5, size=8)) +
  labs(x="Patients", y="Firmicutes/Bacteroidetes Ratio",
       subtitle = paste("Mann Whitney p-value:",p_val))
ggsave(file="Results/Abundances/Ratio_Firmi_Bacteroi/Ratio_barplot.png",width=8,height=4, dpi=300) 
dev.off()


####### JITTER PLOT (with means)
set.seed(2)
ggplot(data=ratio_fb, aes(x=Condition, color=Condition,y=Ratio)) +
  theme_bw(base_size =9) +
  scale_color_manual(values = c("VEDOSS"="chartreuse","SSc"="coral")) +
  facet_grid(.~Condition, scales = "free_x", space="free")+
  theme(panel.spacing.x = unit(20,"pt"))+
  scale_x_discrete (expand = c(0.2,0.3) ) +
  scale_y_sqrt(breaks=c(0.5,1,1.5,3,5,seq(10,80,10)) ) +
  geom_errorbar(aes(ymin = Ratios_Mean, # to add the mean line
                    ymax = Ratios_Mean),
                size=0.35,width = 0.35, color= "black") +
  geom_errorbar(aes(ymax= Ratios_Mean + Ratios_st_err, # to add the standard deviation
                    ymin= ifelse(Ratios_Mean - Ratios_st_err < 0, # the if else is needed to avoid geom bar below zero
                                 0, Ratios_Mean - Ratios_st_err)),
                width=.1, color="black", size= 0.15) +
  geom_jitter(width = 0.25, size=0.5, show.legend = F) +
  guides(color="none") +
  theme(axis.text.x=element_text(angle=0, vjust=0.5, size=8),
        axis.text.y=element_text(size=6)) +
  labs(x="", y="Firmicutes/Bacteroidetes Ratio", caption = paste("Mann Whitney p-value:",p_val) )
ggsave(file="Results/Abundances/Ratio_Firmi_Bacteroi/Ratios_jitter_mean.png",width=4,height=3.5, dpi=300) 
dev.off()

suppressWarnings(rm(con, res, ratio_fb, Ratios_Mean, Ratios_st_err,data_fb, p_val))


######################## SETTING THE GROUP COLORS ######################

# same function down there will search the colors from here
tabella_colore<-as.data.frame(cbind(as.character(sample_data(data)$Condition),as.character(sample_data(data)$Condition)))
colnames(tabella_colore)<-c("Gruppo","Colore")
colors <- gsub("SSc","coral",tabella_colore$Colore)
colors <- gsub("VEDOSS","chartreuse",colors)


######################## HIERARCHICAL CLUSTERING ###################

# euclidean
c<-hclust(dist(t(sqrt(otu_table(data.prop)))))
c<-as.dendrogram(c)
labels_colors(c) <- colors[order.dendrogram(c)]
png(file="Results/Hierarchical_clustering/Hierarchical_cluster_Hellinger_ASV.png",width=2500,height=1800, res=300)
par(mar=c(6,4,5,4), cex.lab=1, cex.main=1.4, cex.sub=1.3)
plot(c,main="Community structure using Hellinger distance",
     sub="SSc = orange     VEDOSS = green")
dev.off()

# Bray Curtis
c<-hclust(vegan::vegdist(t(sqrt(otu_table(data.prop))),method = "bray"))
c<-as.dendrogram(c)
labels_colors(c) <- colors[order.dendrogram(c)]
png(file="Results/Hierarchical_clustering/Hierarchical_cluster_Bray_sqrt_prop_normalized_ASV.png",width=2500,height=1800, res=300)
par(mar=c(6,4,5,4), cex.lab=1, cex.main=1.35, cex.sub=1.3)
plot(c,main="Community structure using Bray-Curtis distance on sqrt proportional ASVs",
     sub="SSc = orange     VEDOSS = green")
dev.off()

suppressWarnings(rm(c,color_table,labels_colors))


########################## ALFA DIVERSITY ############################

# no normalization according to phyloseq https://www.bioconductor.org/packages/release/bioc/vignettes/phyloseq/inst/doc/phyloseq-FAQ.html#should-i-normalize-my-data-before-alpha-diversity-analysis

pAlpha<-plot_richness(data, measures=c("Shannon", "Observed"), x="Condition")
pAlpha
# plot_richness( ) compute diversity like estimate_diversity( )
H<-dplyr::filter(pAlpha$data, variable=="Shannon")
obs<-dplyr::filter(pAlpha$data, variable=="Observed")
# adding evanness
{identical(H$Sample_ID, obs$Sample_ID) # TRUE
  ev<-H
  ev$value<-(H$value)/log((obs$value))
  ev$variable<-rep("Evenness")
  # updating
  New_data<-rbind.data.frame(obs,H,ev)
  pAlpha$data<-New_data
  pAlpha$data$variable<-gsub("Observed","Observed richness",pAlpha$data$variable)
  pAlpha$data$variable<-factor(pAlpha$data$variable,levels = c("Observed richness","Shannon","Evenness"))
}

pAlpha + geom_boxplot(data=pAlpha$data, aes(x=Condition, y=value, color=NULL), alpha=0.1) + theme_bw() + 
  labs(x="Condition", title="Alpha diversity between VEDOSS and SSc patients") +
  guides(fill="none", color="none") + theme(axis.text.x= element_text(angle=30, vjust=1, hjust=1, size=11)) +
  stat_compare_means(aes(group = Condition), label="p.format", method = "wilcox.test", label.x= 0.65, size=3.5, label.y.npc = "top", vjust=-0.5, hjust=-0.4)
ggsave(file="Results/Alfa_diversity_with_Mann_Withn_Wilcox.png", width = 6,height =6, dpi=300)

# just to test the plotted p value
alphadt<- as.data.frame(pAlpha$data) # the column "value" contains the alpha value
Obser_value<-filter(alphadt, variable=="Observed richness")
factor<-Obser_value$Condition
wilcox.test(Obser_value$value~factor)

rm(pAlpha, alphadt, H, ev, obs, Obser_value, New_data, factor)


######################## BETA DIVERSITY  #######################

suppressWarnings(rm(ASV.prop))

{ASV.prop<-as.data.frame(otu_table(data.prop))
  ASV.genus.prop<-as.data.frame(otu_table(data.genus.prop))
  ASV.fam.prop<-as.data.frame(otu_table(data.fam.prop))
  ASV.class.prop<-as.data.frame(otu_table(data.class.prop))
  ASV.order.prop<-as.data.frame(otu_table(data.order.prop))
  ASV.phy.prop<-as.data.frame(otu_table(data.phy.prop))
}

#### PERMANOVA
metadata<-as(sample_data(data.prop),"data.frame")

sample_OTU<-as.data.frame(t(sqrt(ASV.prop))) # samples has to be on rows --> t
perm_ASV<- vegan::adonis(sample_OTU ~Condition, data=metadata, permutations = 9999, method="euclidean")
perm_ASV$aov.tab$`Pr(>F)`[1]
perm_ASV_H<-perm_ASV$aov.tab$`Pr(>F)`[1] # needed later for plot

sample_OTU<-as.data.frame(t(sqrt(ASV.genus.prop)))
perm_g<- vegan::adonis(sample_OTU ~Condition, data=metadata, permutations = 9999, method="euclidean")
perm_g$aov.tab$`Pr(>F)`[1]
perm_g_H<-perm_g$aov.tab$`Pr(>F)`[1] 

sample_OTU<-as.data.frame(t(sqrt(ASV.fam.prop)))
perm_f<- vegan::adonis(sample_OTU ~Condition, data=metadata, permutations = 9999, method="euclidean")

sample_OTU<-as.data.frame(t(sqrt(ASV.class.prop)))
perm_o<- vegan::adonis(sample_OTU ~Condition, data=metadata, permutations = 9999, method="euclidean")

sample_OTU<-as.data.frame(t(sqrt(ASV.order.prop)))
perm_c<- vegan::adonis(sample_OTU ~Condition, data=metadata, permutations = 9999, method="euclidean")

sample_OTU<-as.data.frame(t(sqrt(ASV.phy.prop)))
perm_p<- vegan::adonis(sample_OTU ~Condition, data=metadata, permutations = 9999, method="euclidean")

beta<-rbind(perm_ASV$aov.tab[1,],perm_g$aov.tab[1,],perm_f$aov.tab[1,],perm_o$aov.tab[1,],perm_c$aov.tab[1,],perm_p$aov.tab[1,])
row.names(beta)<-c("Raw_ASV","Genera","Families","Orders","Classes","Phyla")
beta
write.csv2(beta, file="Results/Beta_div/Beta_divers_permanova_Helling.csv",quote=F,row.names = T)


### PLUS: checking it with Bray too
suppressWarnings(rm(sample_OTU,perm_ASV))
sample_OTU<-as.data.frame(t(sqrt(ASV.prop))) # samples has to be on rows --> t
perm_ASV<- vegan::adonis(sample_OTU ~Condition, data=metadata, permutations = 9999, method="bray")
write.csv2(as.data.frame(perm_ASV$aov.tab), file="Results/Beta_div/Beta_divers_permanova_BRAY_on_ASV.csv",quote=F,row.names = T)


# Perform an ANCOVA-like test to determine if the variances differ by groups --> betadispersion test on distance
# on ASV
BC.dist<-vegan::vegdist(t(sqrt(ASV.prop)), distance="euclidean")
disper<-vegan::betadisper(BC.dist,metadata$Condition)
disp_ASV<-vegan::permutest(disper, permutations=9999)
disp_ASV
write.csv2(disp_ASV$tab, file="Results/Beta_div/Beta_dispersion_permanova_Helling.csv",quote=F,row.names = T)

rm(beta, perm_g, perm_f, perm_o, perm_c, perm_p, perm_ASV)


########################### PCoA BRAY CURTIS #####################

# on ASV
data.prop.labels<-data.prop
sample_names(data.prop.labels)<-sample_data(data.prop)$Sample_name
{data.sqrt_prop<-transform_sample_counts(data.prop.labels, sqrt) # square root of proportion
  DistBC = phyloseq::distance(data.sqrt_prop, method = "euclidean")
  ordBC = ordinate(data.sqrt_prop, method = "PCoA", distance = DistBC)
  eigval<-ordBC$values$Eigenvalues # to get eigen values of every PC
  eigval<- round((eigval/sum(eigval))*100, 1) # to get variation explained by every PC
}
plot_ordination(data.sqrt_prop, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  geom_point(size=3) + theme_classic(base_size = 14) + stat_ellipse(size=0.2) + 
  geom_text(aes(label=sample_names(data.sqrt_prop)), color="black", size=3, show.legend = FALSE) +
  labs(title="PCoA with Hellinger distance\n (euclidean on Hellinger transformed ASV)", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"))
ggsave(file="Results/Beta_div/PCoA_Beta_diversity_Hellinger_on_ASV.png", width = 8, height = 6, dpi=300)
# without ellipses
plot_ordination(data.sqrt_prop, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  geom_point(size=3) + theme_classic(base_size = 14) + 
  geom_text(aes(label=sample_names(data.sqrt_prop)), color="black", size=3, show.legend = FALSE) +
  labs(title="PCoA with Hellinger distance\n (euclidean on Hellinger transformed ASV)",
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"), subtitle = paste("PERMANOVA Pr(>F) =",perm_ASV_H))
ggsave(file="Results/Beta_div/PCoA_Beta_diversity_Hellinger_ASV_no_ellipse.png", width = 8, height = 6, dpi=300)
# without names
plot_ordination(data.sqrt_prop, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  geom_point(size=3) + theme_classic(base_size = 14) + stat_ellipse(size=0.2) +
  labs(title="PCoA with Hellinger distance\n (euclidean on Hellinger transformed ASV)", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"), subtitle = paste("PERMANOVA Pr(>F) =",perm_ASV_H))
ggsave(file="Results/Beta_div/PCoA_Beta_diversity_Hellinger_on_ASV_points.png", width = 8, height = 6, dpi=300)

suppressWarnings(rm(data.sqrt_prop_perm, eigval, DistBC, ordBC,data.prop.labels))


# ASV in 3D
{Dist<- vegdist(t(otu_table(data.sqrt_prop)), method = "euclidean")                                                                                                      
  obj<-ecodist::pco(Dist)
  matrix<-obj[["vectors"]]
  row.names(matrix)<-sample_names(data.sqrt_prop)
}
rgl::open3d(windowRect=c(25,25,1200,1200))
pca3d::pca3d(matrix, col=colors, axes.color = "darkgray",
             radius=1.5, show.shadows = T, show.plane = F, show.centroids = F)
rgl::rgl.viewpoint(theta = -40.8, phi = 30.8, fov = 120, zoom = 0.34)
rgl::legend3d("topleft", c("VEDOSS", "SSc"), 
              col=c(3,2), pch = c(19, 19), magnify=0.6)
# pca3d::listShapes()
rgl::rgl.snapshot("temp.png")
temp<-png::readPNG("temp.png")
# install.packages("pdftools") # it needs also "sudo apt install libpoppler-cpp-dev"
png::writePNG(temp, "Results/Beta_div/PCoA_Hellinger_3D_on_ASV_Condition.png", dpi = 300)
## rgl::snapshot3d(file="PCoA3D.png", width=2500, height=2000)
# rgl::rgl.postscript("randu.eps") # save in eps format and then convert it throug Ghost Script command
# cmd <-"gs -dSAFER -dBATCH -dNOPAUSE -dEPSCrop -sDEVICE=png16m -r300 -sOutputFile='Bray Curtis 3D su ASV.png' randu.eps"
# system(cmd)
unlink("temp.png")
rgl::close3d()

# again but on genera
{data.prop.labels<-data.genus.prop
  sample_names(data.prop.labels)<-sample_data(data.genus.prop)$Sample_name
  data.sqrt_prop<-transform_sample_counts(data.prop.labels, sqrt) # square root of proportion
  DistBC = phyloseq::distance(data.sqrt_prop, method = "euclidean")
  ordBC = ordinate(data.sqrt_prop, method = "PCoA", distance = DistBC)
  eigval<-ordBC$values$Eigenvalues
  eigval<- round((eigval/sum(eigval))*100, 1)
}
plot_ordination(data.sqrt_prop, ordBC, color = "Condition") +
  scale_color_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  geom_point(size=3) + theme_classic(base_size = 14) + stat_ellipse(size=0.2) + 
  labs(title="PCoA with Hellinger distance\n (euclidean on Hellinger transformed genera)", 
       color="Condition", x=paste("PC1: ",eigval[1],"% variation"), y=paste("PC2: ",eigval[2],"% variation"), subtitle = paste("PERMANOVA Pr(>F) =",perm_g_H))
ggsave(file="Results/Beta_div/PCoA_Beta_diversity_Hellinger_on_genera.png", width = 8, height = 6, dpi=300)

suppressWarnings(rm(data.sqrt_prop_perm, eigval, DistBC, ordBC,data.prop.labels))


################## DA WITH DESEQ2 ##################

if(! "unfiltered_data" %in% ls() ){
  cat("\nDid you perform the filtering step yet?\n", fill = T)
  Sys.sleep(2)
}


dir.create("Results/DA_DESeq2")

##### STARTING THE DIFFERENTIAL ANALYSIS
suppressWarnings(rm(data_pruned, data.genus_pruned))
data_pruned<- prune_taxa(taxa_sums(data) > 10, data) 
# Trimming under sum of 10 (see DeSeq2 tutorial) and preparing new data (other ASV may be selected after glomming)

Table_tot<-NULL
Res_tot<-NULL

for( t in c("Genus","Family","Class","Order","Phylum") ){
  cat("\nWorking on",t,"level...\n")
  suppressWarnings(rm(list=c("d", "d.prop", "Taxa.d", "res","DE", "target", "r", "r_level")))
  d <- tax_glom(data_pruned, taxrank = t, NArm = F)
  d.prop<- transform_sample_counts(d, function(x) x/sum(x)*100)
  
  if(t=="Genus"){ # updating missing names (NA and uncultured) but only for genus level
    taxa_temp<-as.data.frame(tax_table(d))
    for( x in 1: length(which(taxa_temp$Genus=="uncultured")) ) {
      taxa_temp$Genus[which(taxa_temp$Genus=="uncultured")[1]]<-paste("uncultured_ f",taxa_temp[which(taxa_temp$Genus=="uncultured")[1],"Family"])}
    for( x in 1: length(which(taxa_temp=="uncultured_ f uncultured")) ) {
      taxa_temp$Genus[ which(taxa_temp$Genus=="uncultured_ f uncultured")[1] ]<-paste("uncultured_ o",taxa_temp[which(taxa_temp$Genus=="uncultured_ f uncultured")[1],"Order"])}
    for( x in 1: length(which(is.na(taxa_temp$Genus))) ) {
      taxa_temp$Genus[ which(is.na(taxa_temp$Genus))[1] ]<-paste("NA_ f",taxa_temp[which(is.na(taxa_temp$Genus))[1],"Family"])}
    for( x in 1: length(which(taxa_temp=="NA_ f NA")) ) {
      taxa_temp$Genus[ which(taxa_temp$Genus=="NA_ f NA")[1] ]<-paste("NA_ o",taxa_temp[which(taxa_temp$Genus=="NA_ f NA")[1],"Order"])}
    for( x in 1: length(which(duplicated(taxa_temp$Genus[taxa_temp$Genus=="NA_ o NA"]))) ) {
      taxa_temp$Genus[ which(taxa_temp$Genus=="NA_ o NA")[1] ]<-paste("NA_ o NA",x+1) }
    tax_table(d)<-as.matrix(taxa_temp)
    tax_table(d.prop)<-as.matrix(taxa_temp)
    rm(taxa_temp) }
  
  ### starting the analysis
  DEseq_data<-phyloseq_to_deseq2(d, ~Condition)
  DE<-DESeq(DEseq_data)
  res<-results(DE, contrast= c("Condition", "SSc", "VEDOSS"))
  res = res[order(res$padj, na.last=NA), ]
  res<-res[(res$padj < 0.05) & abs(res$log2FoldChange)>1,]
  res<-res[res$baseMean > 100, ] # arbitrary threshold to avoid the most noisy result
  res
  if(length(res$log2FoldChange)>0){ # if there are results...
    cat(paste(length(res$log2FoldChange),"results for the",t,"level\n"))
    Sys.sleep(1)
    r<-as.data.frame(res)
    r$ASV<-row.names(r)
    Taxa.d<-as.data.frame(tax_table(d))
    Taxa.d$ASV<-row.names(Taxa.d)
    r<-dplyr::left_join(r, Taxa.d, by="ASV")
    r$Kingdom<-NULL
    r$Species<-NULL
    assign(paste(t,"results",sep="_"), r)
    write.csv2(r, file=paste0("Results/DA_DESeq2/DA_",t,"_ratio_SSc_vs_VEDOSS.csv"), row.names = F, quote=F, na = "")
    r_level<-r
    r_level[, "Taxon"]<- rep(t)
    Res_tot<-rbind.data.frame(Res_tot,r_level)
    ### single box plots
    target<-r[[t]]
    colnames(tax_table(d.prop))[colnames(tax_table(d.prop))==t]<-"Aimed_taxa"
    target<-subset_taxa(d.prop, Aimed_taxa %in% target) # cannot use t %in% target in this function, then it's scripted in this way
    Table_DE<-psmelt(target)
    colnames(Table_DE)[colnames(Table_DE)=="Aimed_taxa"]<-t # restored the original name
    Table_DE$ASV<-NULL
    # Table_DE$Abundance<-sqrt(Table_DE$Abundance) # then sqrt of proportion
    assign(paste("Table_DE_plot",t,sep="_"), Table_DE)
    ### appending to unique box plot
    index<- which(colnames(Table_DE)=="Kingdom") : which(colnames(Table_DE)==t)
    index<- index[-length(index)] # removing the last index, regarding the taxa of interest
    Table_DE[,index]<-NULL
    Table_DE$Taxa<-t
    colnames(Table_DE)[colnames(Table_DE)==t]<-"Bacteria"
    Table_tot<-rbind.data.frame(Table_tot, Table_DE)
  } else {
    cat("Any results for the",t,"level\n")
    Sys.sleep(1)
  }
}

View(Res_tot)
write.csv(Res_tot, file="Results/DA_DESeq2/Every_result_DESeq2.csv", row.names = F)
write.xlsx(Res_tot, file="Results/DA_DESeq2/Every_result_DESeq2.xlsx", showNA = F, col.names = T)

ggplot(Table_tot, aes(x= Bacteria, y=Abundance, fill=Condition)) + 
  facet_grid(~factor(Taxa,levels = c("Phylum","Class","Order","Family","Genus")), scales = "free_x", space="free") +
  geom_boxplot(width=0.8) + theme_bw(base_size = 15) +
  theme(strip.text.x=element_text(size=14,colour="black")) + 
  scale_fill_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  guides( fill=guide_legend(nrow=1) ) +
  theme(legend.margin=margin(-25, 0, 0, 0), legend.position="bottom", 
        legend.key.size=unit(0.8,"cm"), legend.text=element_text(size=15),
        axis.text.x = element_text(angle = 50, vjust=1, hjust=1, size=11), 
        axis.text.y = element_text(size=12), plot.title= element_text(size=18),
        panel.grid.minor.y= element_blank() ) +   
  scale_x_discrete(expand=c(-0.2, 1)) +
  labs(title= "Differently abundant Taxa", y="Proportional Abundance", 
       fill="Condition", x="")
ggsave(filename = "Results/DA_DESeq2/DA_Condition_every_result.png", width = 15, height = 8, dpi=300)
dev.off()


Table_tot2<-subset(Table_tot, ! Bacteria %in% c("uncultured","Streptococcaceae","Rhodospirillales","Alphaproteobacteria")) # to remove redundant results
ggplot(Table_tot2, aes(x= Bacteria, y=Abundance, fill=Condition)) + 
  facet_grid(~factor(Taxa,levels = c("Phylum","Class","Order","Family","Genus")), scales = "free_x", space="free") +
  geom_boxplot(width=0.8) + theme_bw(base_size = 15) +
  scale_fill_manual(values=c("SSc"="coral","VEDOSS"="chartreuse")) +
  theme(strip.text.x=element_text(size=14,colour="black")) + 
  guides( fill=guide_legend(nrow=1) ) +
  theme(legend.margin=margin(-25, 0, 0, 0), legend.position="bottom", 
        legend.key.size=unit(0.8,"cm"), legend.text=element_text(size=15),
        axis.text.x = element_text(angle =30, vjust=1, hjust=1, size=12), 
        axis.text.y = element_text(size=10), 
        plot.title= element_text(size=18),
        panel.grid.minor.y= element_blank(),
        plot.margin =  margin(t=5,r=5,b=5, l=5) ) +  
  scale_x_discrete(expand=c(-0.2, 1)) +
  scale_y_sqrt(breaks=c(0.1, 0.5, 1,2,3,5, seq(7,40,3),seq(40,max(Table_tot$Abundance),4))) +
  labs(title= "Differently abundant Taxa", y="Proportional Abundance", 
       fill="Condition", x="")
ggsave(filename = "Results/DA_DESeq2/DA_Condition_no_redundants.png", width = 14, height = 8, dpi=300)
dev.off()

system(" echo 'Every result UNDER the arbitrary threshold of basemean=100 has been removed in order to avoid the most noisy results' > Results/DA_DESeq2/NB.txt ")

# for comparison with splsda ...
Genera.DESEQ2<-unique(Table_tot[Table_tot$Taxa=="Genus","Bacteria"])


################# PLS-DA and sPLS-DA ###########################

dir.create("Results/PLS_DA")

# BiocManager::install('mixOmics')
data.selected<-data.genus.prop
metadata_PLSDA<-as(sample_data(data.selected),"data.frame")

X <- as.matrix(t(otu_table(data.selected)))
Y <- as.factor(metadata_PLSDA$Condition)

my.splsda <- splsda(X, Y, ncomp = 10)

gc()
set.seed(1)
perf.splsda <- perf(my.splsda, validation = "Mfold", # to assest the optimal number of comp
                    folds = 10, nrepeat = 5*(dim(X)[1]), cpus = 7,
                    progressBar = TRUE, auc = TRUE)

perf.splsda$choice.ncomp
comp<-perf.splsda$choice.ncomp[6] # centroid distance   # 3 on max.dist, 6 on centroid (6 chosen)

png(filename = "Results/PLS_DA/Error for each component PLS-DA", width = 2500, height = 1800, res=300)
plot(perf.splsda, col = color.mixo(5:7), sd = TRUE, legend.position = "horizontal")
title(main="Classification rate error \n for each component used to compute PLS-DA")
dev.off()

my.splsda <- splsda(X, Y, ncomp = comp)

n= 2 # choose the component to use depending on clustering efficiency in plot
png(filename = paste("Results/PLS_DA/normal_PLS_DA_comp_1_and", n, sep="_"), width = 2500, height = 1500, res=300)
plotIndiv(my.splsda, comp = c(1,n), pch = c(1,1),
          group = metadata_PLSDA$Condition, ind.names = F, ellipse = TRUE, legend = TRUE, 
          title = paste0("PLSDA between SSc and VEDOSS \n on scaled proportional genus data \n (computed with ", comp, " components, plotted on comp 1 and ", n,")"))
dev.off()


################ sPLS-DA for variable selection

X <- as.matrix(t(otu_table(data.selected)))
Y <- as.factor(metadata_PLSDA$Condition)

# cutting out same sample for test (otherwise clear overfitting during the test)
set.seed(1)
train <- sample(1:nrow(X), 35) # select a huge number of sample
train
test <- setdiff(1:nrow(X), train)

{X.test <- X[test,]
  X <- X[train, ]
  Y.test <- Y[test]
  Y<- Y[train]
  metadata_PLSDA2<-metadata_PLSDA[row.names(X),]
}

possible.pool<- seq(5, 35, 5) # for test.keepX
gc()
set.seed(1)
my.tuned.splsda <- tune.splsda(X, Y, ncomp = comp, validation = 'Mfold',
                               folds = 10, nrepeat = 4*(dim(X)[1]), cpus = 8, # use repeated cross-validation
                               dist = 'centroids.dist', test.keepX =  possible.pool, # testing from 10 to 1/5 MAX number of variables
                               measure = "BER",
                               progressBar = T) # use balanced error rate of dist measure

my.tuned.splsda$choice.ncomp$ncomp # 2
png(filename = paste("Results/PLS_DA/Error_of_splsda_depending_from_computing",comp,"components", sep="_"), width = 1500, height = 2000, res=300)
plot(my.tuned.splsda, col = color.jet(comp))
dev.off()
optimal.comp<-my.tuned.splsda$choice.ncomp$ncomp

optimal.keepX <- my.tuned.splsda$choice.keepX[1:optimal.comp]
optimal.keepX # 30 on comp 1 and 35 on comp2

final.splsda<-splsda(X,Y, ncomp=optimal.comp, keepX = optimal.keepX)
n=2 # choose which component plot depending on plot
# png(filename = paste("Results/PLS_DA/sparse_PLS_DA_comp_1_and",n, sep="_"), width = 2500, height = 1500, res=300)
# plotIndiv(final.splsda, comp = c(1,n), group = metadata_PLSDA2$Condition, ind.names = TRUE, legend = TRUE, ellipse = TRUE,
#           title = paste0("sparse PLSDA between SSc and VEDOSS \n on scaled proportional genus data \n (computed with ", optimal.comp, " components, plotted on comp 1 and ", n,")"))
# dev.off()
final.splsda$prop_expl_var
ggplot(mapping = aes(x=final.splsda$variates$X[,"comp1"], y=final.splsda$variates$X[,"comp2"], color=final.splsda$Y)) +
  geom_point(size=3) + theme_classic(base_size = 14) + stat_ellipse(size=0.2) +
  # geom_text(mapping = aes(label=row.names(final.splsda$X)), color="black", size=2.3) +
  scale_colour_manual(values = c("SSc" = "coral", "VEDOSS" = "chartreuse"))+
  labs(title="sparse PLS-DA between SSc and VEDOSS subjects", 
       subtitle=paste0("on scaled proportional genus data \n (computed with ", optimal.comp, " components, plotted on comp 1 and ", n,")"),
       caption = paste0("selected ",optimal.keepX[1]," genera on LC1 and ",optimal.keepX[2]," genera on LC2"),
       color="Condition", x=paste("X-Var1: ",round(final.splsda$prop_expl_var$X[1]*100,digits = 2),"% variation"),
       y=paste("LC2: ",round(final.splsda$prop_expl_var$X[2]*100,digits = 2),"% variation"))
ggsave(filename = paste("Results/PLS_DA/sparsePLS-DA on comp 1 and",n,".png"), width = 8, height = 6, dpi=300) 


################ plotting loadings

loadings<-as.data.frame(final.splsda$loadings$X)
identical(row.names(Taxa.genus.update[row.names(loadings),]),row.names(loadings))
loadings$Genus<-Taxa.genus.update[row.names(loadings),"Genus"]

a<-loadings[loadings$comp1!=0,]
{tax_a<-Taxa.genus.update
  tax_a$ASV<- row.names(tax_a)
  tax_a<-subset(tax_a, ASV %in% row.names(a))
  tax_a<-tax_a[row.names(a),]
  identical(tax_a$ASV,row.names(a))
  a$Genus<-tax_a$Genus
}

a$comp1<-as.numeric(a$comp1)
a<-a[order(abs(a$comp1)),]
a$Genus[duplicated(a$Genus)] <-paste(a$Genus[duplicated(a$Genus)],"2",sep="_")
a$Genus <- factor(a$Genus, levels = a$Genus) # otherwise it would be re-ordered in plot
ggplot(mapping=aes(x=a$Genus,y=a$comp1)) + geom_bar(stat = "identity", width = 0.6) + theme_bw(base_size = 14) +
  theme(axis.text.x = element_text(angle = 50, size = 11, hjust = 1, vjust = 1)) +
  labs(x="Selected genera on component 1", 
       y="loadings", title = "Loadings of selected genera for component 1 in sPLSDA", 
       caption="\n dotted lines are plot at 50% of both min and max loadings value") +
  geom_hline(yintercept = max(a$comp1)/2, colour="red", linetype="longdash") +
  geom_hline(yintercept = 0, size= 1) +
  geom_hline(yintercept = min(a$comp1)/2, colour="red", linetype="longdash") +
  theme(plot.margin = unit(c(1,0.5,1,1.8), "cm"))
ggsave(filename = "Results/PLS_DA/Loadings of choosen genera for sPLSDA comp 1.png", width = 14, height = 8, dpi=300)

b<-loadings[loadings[[n]]!=0,]
{tax_b<-Taxa.genus.update
  tax_b$ASV<- row.names(tax_b)
  tax_b<-subset(tax_b, ASV %in% row.names(b))
  tax_b<-tax_b[row.names(b),]
  identical(tax_b$ASV,row.names(b))
  b$Genus<-tax_b$Genus
}

b[,n]<-as.numeric(b[,n])
b<-b[order( abs(b[,n])) ,]
b$Genus <- factor(b$Genus, levels = b$Genus)
ggplot(mapping=aes(x=b$Genus,y=b[,n])) + geom_bar(stat = "identity", width = 0.6) + theme_bw(base_size = 14) +
  theme(axis.text.x = element_text(angle = 50, size = 11, hjust = 1, vjust = 1)) +
  labs(x=paste("Selected genera on component",n), 
       y="loadings", title = paste("Loadings of selected genera for component",n,"in sPLSDA"), 
       caption="\n dotted lines are plot at 50% of both min and max loadings value") +
  geom_hline(yintercept = max(b[,n])/2, colour="red", linetype="longdash") +
  geom_hline(yintercept = 0, size= 1) +
  geom_hline(yintercept = min(b[,n])/2, colour="red", linetype="longdash") +
  theme(plot.margin = unit(c(1,0.5,1,1.8), "cm"))
ggsave(filename = paste("Results/PLS_DA/Loadings_of_choosen_genera_for_sPLSDA_comp",n,".png"), width = 14, height = 8, dpi=300)


############### testing the sPLS-DA model

predict.splsda <- predict(final.splsda, newdata =as.matrix(X.test), dist = "all")

# evaluating the prediction accuracy
predict.comp <- predict.splsda$class$centroids.dist[,n]
predict.comp
table(factor(predict.comp, levels = levels(Y)), as.factor(Y.test))
# now evaluating the prediction accuracy using ONLY the first component
predict.comp1 <- predict.splsda$class$centroids.dist[,1]
predict.comp1
table(factor(predict.comp1, levels = levels(Y)), as.factor(Y.test))


# comparison with DeSeq2 results
Genera.splsda1<-as.character(a$Genus)
Genera.splsda2<-as.character(b$Genus)
suppressWarnings(rm(con))
con<-file("Results/PLS_DA/Common_results_between_splsda_and_Deseq2.txt")
sink(con)
cat("Along the Latent component 1 axis \n", fill=TRUE)
cat(intersect(Genera.DESEQ2, Genera.splsda1), sep = "\n")
cat("\n ############################### \n", fill=TRUE)
cat("Along the Latent component",n,"axis \n", fill=TRUE)
cat(intersect(Genera.DESEQ2, Genera.splsda2), sep = "\n")
sink()
close(con)


##### exporting impostations and values of sPLSDA

suppressWarnings(rm(con))
con<-file("Results/PLS_DA/Settings_and_results_sPLSDA.txt")
sink(con)
cat("Number of training samples and their original number of genera", fill = TRUE)
cat(dim(X), fill = TRUE)
cat("\n Samples casually selected as test (and then discarded from training data set)", fill=TRUE)
cat(row.names(X.test), fill = TRUE)
cat("\n number of components suggested by perf function for normal PLSDA (centroid dist)", fill=TRUE)
cat(perf.splsda$choice.ncomp[3],fill=TRUE) # 6
# cat(6,fill=TRUE)
cat("\n number of components chosen for normal PLSDA (centroid dist)", fill=TRUE)
cat(comp, fill=TRUE)
cat("\n number of components suggested by tune.splsda function for sPLSDA", fill=TRUE)
cat(my.tuned.splsda$choice.ncomp$ncomp, fill=TRUE)
cat("\n number of components chosen for sPLSDA", fill=TRUE)
cat(optimal.comp, fill = TRUE)
cat("\n number of genera selected by tune.splsda function for each chosen component", fill=TRUE)
cat(optimal.keepX, fill=TRUE)
cat("\n Possible number of genera that could be selected by function tune.splsda", fill=TRUE)
cat(possible.pool, fill = TRUE)
cat("\n \n \n ### testing the prediction efficiency of sPLSDA through confusion matrix using ONLY the first component \n", fill=TRUE)
table(factor(predict.comp1, levels = levels(Y)), Y.test)
cat("\n", length(which(predict.comp1!="")),"on", length(predict.comp1), "samples predicted" )
cat("\n \n ### testing the prediction efficiency of sPLSDA through confusion matrix component 1 and",n,"\n", fill=TRUE)
table(factor(predict.comp, levels = levels(Y)), Y.test)
cat("\n", length(which(predict.comp!="")),"on", length(predict.comp), "samples predicted" )
cat("\n \n type of distance used: centroid distance")
sink()
close(con)


rm(a,b,con,tax_a,tax_b, tabella_colore_train, colors_train, loadings,metadata_PLSDA2,predict.comp,predict.comp1,train,X,Y,X.test,Y.test,final.splsda,my.tuned.splsda,predict.splsda,comp,n,test,optimal.comp,optimal.keepX)
gc()


################### ANALYSING LEFSE RESULTS ###########################

dir.create("Results/PICRUST2_LEFSE")

suppressWarnings(rm(a))
a <- read.delim("QIIME/PICRUST2_LEFSE/picrust2/pathways_out/path_abun_unstrat_descrip.tsv.gz") 
Descriptions<-a[,c("pathway","description")]

Significative_functions_LEFSE<- read.delim("QIIME/PICRUST2_LEFSE/Result_LEFSE.res", header=FALSE)
head(Significative_functions_LEFSE, n=4)
head(Descriptions$pathway, n=4) # just a further checking of the row matching (different text format but same information)
colnames(Significative_functions_LEFSE)<-c("Pathway","Log_highest_mean","Class_with_highest_mean","logLDA_score","p-value")
Significative_functions_LEFSE$Pathway<-Descriptions$description
Significative_functions_LEFSE$Pathway_ID<-Descriptions$pathway
head(Significative_functions_LEFSE, n=4)

# if sensed as significative then the logLDA is displayed
Significative_functions_LEFSE<-Significative_functions_LEFSE[!is.na(Significative_functions_LEFSE$logLDA_score),]
write.xlsx(Significative_functions_LEFSE, file="Results/PICRUST2_LEFSE_results/Significantly_different_pathways_METACYC.xlsx", col.names = T, showNA = F, row.names = F)

# modifing names for the plot)
Significative_functions_LEFSE$Pathway<-gsub("&beta;-","", Significative_functions_LEFSE$Pathway, fixed = T)
{Significative_functions_LEFSE$Pathway<-paste("",Significative_functions_LEFSE$Pathway,"") # needed to distance text from lines
  Significative_functions_LEFSE<-Significative_functions_LEFSE[order(abs(as.numeric(Significative_functions_LEFSE$logLDA_score))), ] # order based on the effect size
  Significative_functions_LEFSE$Pathway<-factor(Significative_functions_LEFSE$Pathway, levels = Significative_functions_LEFSE$Pathway) # to prevent alphabetical re-sorting
}
# inverting the values of a group to make a simmetric plot
Significative_functions_LEFSE$logLDA_score[Significative_functions_LEFSE$Class_with_highest_mean=="VEDOSS"]<- -Significative_functions_LEFSE$logLDA_score[Significative_functions_LEFSE$Class_with_highest_mean=="VEDOSS"]


# plotting every result
ggplot(data=Significative_functions_LEFSE, aes(y=Pathway, x=as.numeric(logLDA_score), fill=Class_with_highest_mean)) +
  geom_bar(stat = "identity", width = 1, color="black" ) + labs(x="log LDA score", y="", fill="") +
  geom_text(aes(x= 0, label=Pathway), hjust = ifelse(Significative_functions_LEFSE$Class_with_highest_mean=="SSc",1,0), size=3.2) +
  scale_fill_manual(values=c("VEDOSS"="chartreuse", "SSc"="coral")) +
  theme_classic(base_size = 16) +
  scale_x_continuous(breaks = c(-3,-2,-1, 1, 2, 3))+
  theme(panel.grid.major.x = element_line(color = "grey", size = 0.3)) +
  theme(axis.text.y=element_blank(), 
        axis.ticks.y = element_blank(),
        axis.line.y = element_blank(),
        legend.text = element_text(size = 15),
        legend.margin = margin(-10,0,0,0)) +
  theme(legend.position = "bottom")
ggsave(filename = "Results/PICRUST2_LEFSE_results/PICRUST2_LEFSE_plot_diff_METACYC_every_result.png", width = 11, height = 8, dpi = 300)

#plotting only results over 3
# Significative_functions_LEFSE_3<-Significative_functions_LEFSE[abs(Significative_functions_LEFSE$logLDA_score)>3,]
# ggplot(data=Significative_functions_LEFSE_3, aes(y=Pathway, x=as.numeric(logLDA_score), fill=Class_with_highest_mean)) +
#   geom_bar(stat = "identity", width = 1, color="black" ) + labs(x="log LDA score", y="", fill="") +
#   geom_text(aes(x= 0, label=Pathway), hjust = ifelse(Significative_functions_LEFSE$Class_with_highest_mean=="SSc",1,0), size=3.2) +
#   scale_fill_manual(values=c("VEDOSS"="chartreuse", "SSc"="coral")) +
#   theme_classic(base_size = 16) +
#   scale_x_continuous(breaks = c(-3,-2,-1, 1, 2, 3))+
#   theme(panel.grid.major.x = element_line(color = "grey", size = 0.3)) +
#   theme(axis.text.y=element_blank(),
#         axis.ticks.y = element_blank(),
#         axis.line.y = element_blank(),
#         legend.text = element_text(size = 15),
#         legend.margin = margin(-10,0,0,0)) +
#   theme(legend.position = "bottom")
# ggsave(filename = "Results/PICRUST2_LEFSE/PICRUST2_LEFSE_plot_diff_METACYC_every_result.png", width = 9, height = 4, dpi = 300)

system('touch Results/PICRUST2_LEFSE_results/no_result_over_3')

rm(Significative_functions_LEFSE, a)

##################### R AND PACKAGES VERSION #########################

### if on Windows, change "$otherPkgs" with "$loadedOnly"

package<-sessionInfo()

con <- file("Results/R_version_and_packages.txt")
sink(con, append = TRUE)

cat(package$R.version$version.string)
cat("   running on", package$running)
cat("\n", "\n", fill=TRUE)
package$otherPkgs$DESeq2[c(1,4)]
cat("\n", "\n", fill=TRUE)
package$otherPkgs$phyloseq[1:2]
cat("\n", "\n", fill=TRUE)
package$otherPkgs$ggplot2[1:2]
cat("\n", "\n", fill=TRUE)
package$otherPkgs$vegan[c(1,3)]
cat("\n", "\n", fill=TRUE)
print("Dendextend")
packageVersion("dendextend")
cat("\n", "\n", fill=TRUE)
package$otherPkgs$pca3d[c(1,4)]
cat("\n", "\n", fill=TRUE)
package$otherPkgs$mixOmics[c(1,4)]
cat("\n \n \nEvery package: \n", fill=TRUE)
print(package$otherPkgs)

sink()
close(con)
suppressWarnings(rm(con))